{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWGF6cN1il+z2njkqFIWcs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/N-Haritha16/LLM-phi3-lora-finetuning/blob/main/LLM_LoRA_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAKA4CwkvnNm",
        "outputId": "637d6e52-ebea-45c3-a04f-e306ca051ae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'LLM-phi3-lora-finetuning'...\n",
            "remote: Enumerating objects: 184, done.\u001b[K\n",
            "remote: Counting objects: 100% (184/184), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 184 (delta 62), reused 153 (delta 42), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (184/184), 5.70 MiB | 7.72 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "/content/LLM-phi3-lora-finetuning\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!rm -rf LLM-phi3-lora-finetuning\n",
        "!git clone https://github.com/N-Haritha16/LLM-phi3-lora-finetuning.git\n",
        "%cd /content/LLM-phi3-lora-finetuning\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"transformers>=4.37.0\" \"trl>=0.8.0\" bitsandbytes accelerate\n",
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ym_YFQMwBeh",
        "outputId": "92731275-aa55-468c-89a9-83d7a181fe04"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers>=4.37.0 in /usr/local/lib/python3.12/dist-packages (4.57.5)\n",
            "Requirement already satisfied: trl>=0.8.0 in /usr/local/lib/python3.12/dist-packages (0.26.2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37.0) (3.20.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37.0) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37.0) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37.0) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37.0) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37.0) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37.0) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.37.0) (4.67.1)\n",
            "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from trl>=0.8.0) (4.0.0)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl>=0.8.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl>=0.8.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl>=0.8.0) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl>=0.8.0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl>=0.8.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.8.0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.37.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.37.0) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.37.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.37.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.37.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.37.0) (2026.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.8.0) (3.13.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl>=0.8.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl>=0.8.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl>=0.8.0) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.8.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.8.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.8.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.8.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.8.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.8.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.8.0) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl>=0.8.0) (1.17.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (4.57.5)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (4.0.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (0.18.0)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.26.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (1.12.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.49.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.23.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (6.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (4.67.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 3)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 3)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirements.txt (line 3)) (0.70.16)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft->-r requirements.txt (line 4)) (5.9.5)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 8)) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 8)) (3.1.46)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 8)) (4.5.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 8)) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 8)) (2.12.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->-r requirements.txt (line 8)) (2.49.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (3.13.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 8)) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 8)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->-r requirements.txt (line 8)) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 2)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 2)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 2)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 2)) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->-r requirements.txt (line 3)) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements.txt (line 3)) (1.22.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 8)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 3)) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, wandb\n",
        "\n",
        "os.environ[\"WANDB_PROJECT\"] = \"llm-phi3-lora-finetune-colab\"\n",
        "\n",
        "wandb.login()  # paste your API key when asked\n",
        "\n",
        "wandb.init(\n",
        "    project=os.environ[\"WANDB_PROJECT\"],\n",
        "    name=\"phi3_qlora_colab_run_1\",\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "q_sul-WPwKbw",
        "outputId": "b1994b99-8a3e-4c1e-f6fc-512515e60ae7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Create a W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Create an account here: https://wandb.ai/authorize?signup=true\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mharithanallamilli1606\u001b[0m (\u001b[33mharithanallamilli1606-patnr-network\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/LLM-phi3-lora-finetuning/wandb/run-20260115_034416-ag0cnv34</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/harithanallamilli1606-patnr-network/llm-phi3-lora-finetune-colab/runs/ag0cnv34' target=\"_blank\">phi3_qlora_colab_run_1</a></strong> to <a href='https://wandb.ai/harithanallamilli1606-patnr-network/llm-phi3-lora-finetune-colab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/harithanallamilli1606-patnr-network/llm-phi3-lora-finetune-colab' target=\"_blank\">https://wandb.ai/harithanallamilli1606-patnr-network/llm-phi3-lora-finetune-colab</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/harithanallamilli1606-patnr-network/llm-phi3-lora-finetune-colab/runs/ag0cnv34' target=\"_blank\">https://wandb.ai/harithanallamilli1606-patnr-network/llm-phi3-lora-finetune-colab/runs/ag0cnv34</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/harithanallamilli1606-patnr-network/llm-phi3-lora-finetune-colab/runs/ag0cnv34?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7e5e369a7620>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/LLM-phi3-lora-finetuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSFxkN2HwigH",
        "outputId": "d84b5652-cd89-4357-ccf5-25ec48c7b7ce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLM-phi3-lora-finetuning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/generate_dataset.py --config config/config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUlZj3gSwlZa",
        "outputId": "63156ddf-af20-4396-c4b2-14c6c917d26b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote 1001 examples to data/raw/mydataset.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/preprocess.py --config config/config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkNa_Ezlw9vG",
        "outputId": "3972df1c-54fd-4b23-8fe8-1c2eec124f68"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer_config.json: 3.44kB [00:00, 23.4MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:01<00:00, 424kB/s]\n",
            "tokenizer.json: 1.94MB [00:00, 164MB/s]\n",
            "added_tokens.json: 100% 306/306 [00:00<00:00, 3.14MB/s]\n",
            "special_tokens_map.json: 100% 599/599 [00:00<00:00, 6.48MB/s]\n",
            "Map: 100% 1001/1001 [00:00<00:00, 1363.99 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 800/800 [00:00<00:00, 43293.81 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 100/100 [00:00<00:00, 21126.80 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 101/101 [00:00<00:00, 22277.28 examples/s]\n",
            "Preprocessing complete\n",
            "Train size: 800\n",
            "Val size  : 100\n",
            "Test size : 101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/LLM-phi3-lora-finetuning\n",
        "!python src/train_lora.py --config config/config.yaml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvFU0qmYxE9T",
        "outputId": "0ded06bd-2616-4ee8-8265-fcc0ed79a957"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLM-phi3-lora-finetuning\n",
            "2026-01-15 03:48:02.956314: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768448882.977831    4493 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768448882.983707    4493 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768448882.999048    4493 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768448882.999073    4493 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768448882.999076    4493 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768448882.999081    4493 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-15 03:48:03.003457: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "config.json: 100% 967/967 [00:00<00:00, 8.54MB/s]\n",
            "model.safetensors.index.json: 16.5kB [00:00, 72.5MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/2.67G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 690k/4.97G [00:01<3:54:56, 353kB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   0% 3.00M/2.67G [00:02<36:18, 1.22MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 26.9M/4.97G [00:02<06:04, 13.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   0% 4.03M/2.67G [00:02<29:53, 1.49MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 30.5M/4.97G [00:02<06:16, 13.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   0% 9.46M/2.67G [00:03<09:57, 4.45MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 44.6M/4.97G [00:03<04:57, 16.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 49.3M/4.97G [00:03<04:32, 18.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 28.8M/2.67G [00:04<04:39, 9.45MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 42.3M/2.67G [00:05<03:34, 12.3MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 71.0M/4.97G [00:05<05:30, 14.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 73.5M/2.67G [00:05<02:01, 21.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 87.3M/2.67G [00:06<01:52, 23.0MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 100M/4.97G [00:06<04:39, 17.4MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 172M/4.97G [00:06<01:49, 44.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 109M/2.67G [00:07<01:45, 24.2MB/s] \u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 240M/4.97G [00:08<01:34, 50.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 137M/2.67G [00:08<01:41, 24.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   7% 331M/4.97G [00:08<00:53, 86.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   8% 377M/4.97G [00:08<00:55, 82.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 148M/2.67G [00:09<01:55, 21.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   9% 453M/4.97G [00:13<02:09, 34.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 193M/2.67G [00:13<02:55, 14.1MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  10% 520M/4.97G [00:13<01:30, 49.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  11% 558M/4.97G [00:13<01:17, 56.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 198M/2.67G [00:13<02:58, 13.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  12% 595M/4.97G [00:14<01:12, 60.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 243M/2.67G [00:17<03:06, 13.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 347M/2.67G [00:17<01:09, 33.3MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  13% 632M/4.97G [00:17<02:32, 28.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 386M/2.67G [00:17<00:56, 40.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  14% 695M/4.97G [00:17<01:44, 40.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  15% 741M/4.97G [00:18<01:23, 50.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  15% 755M/4.97G [00:18<01:34, 44.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 501M/2.67G [00:19<00:44, 48.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 621M/2.67G [00:23<00:51, 39.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 755M/2.67G [00:23<00:29, 64.2MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  16% 776M/4.97G [00:24<04:39, 15.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  19% 951M/4.97G [00:24<01:25, 47.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 835M/2.67G [00:24<00:26, 69.2MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  21% 1.04G/4.97G [00:25<01:08, 57.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 902M/2.67G [00:25<00:24, 71.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 1.01G/2.67G [00:27<00:26, 62.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.05G/2.67G [00:28<00:29, 55.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  22% 1.10G/4.97G [00:28<01:44, 37.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  23% 1.13G/4.97G [00:32<02:30, 25.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.18G/2.67G [00:32<00:32, 46.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 1.25G/2.67G [00:32<00:25, 55.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/4.97G [00:33<01:56, 32.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 1.28G/2.67G [00:33<00:27, 51.4MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  26% 1.32G/4.97G [00:33<01:12, 50.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  28% 1.40G/4.97G [00:33<00:50, 71.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/4.97G [00:34<00:42, 82.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.31G/2.67G [00:34<00:28, 47.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  31% 1.52G/4.97G [00:34<00:32, 105MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  32% 1.59G/4.97G [00:35<00:31, 108MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.35G/2.67G [00:35<00:26, 49.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  33% 1.62G/4.97G [00:35<00:29, 114MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 1.41G/2.67G [00:35<00:21, 58.2MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  34% 1.69G/4.97G [00:35<00:30, 106MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  35% 1.73G/4.97G [00:36<00:27, 118MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 1.43G/2.67G [00:36<00:23, 53.4MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  36% 1.77G/4.97G [00:36<00:26, 120MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 1.45G/2.67G [00:36<00:24, 49.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 1.52G/2.67G [00:37<00:14, 78.2MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  37% 1.84G/4.97G [00:37<00:31, 99.3MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 1.58G/2.67G [00:37<00:11, 95.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  38% 1.91G/4.97G [00:37<00:26, 117MB/s] \u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 1.65G/2.67G [00:38<00:09, 108MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 1.68G/2.67G [00:38<00:08, 113MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 1.74G/2.67G [00:38<00:06, 137MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  39% 1.92G/4.97G [00:38<00:41, 73.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  39% 1.95G/4.97G [00:38<00:38, 78.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  41% 2.02G/4.97G [00:39<00:25, 114MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  42% 2.09G/4.97G [00:39<00:21, 134MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 1.76G/2.67G [00:39<00:12, 74.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 1.83G/2.67G [00:39<00:08, 104MB/s] \u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  43% 2.12G/4.97G [00:39<00:26, 109MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 1.90G/2.67G [00:40<00:07, 108MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 1.94G/2.67G [00:40<00:06, 120MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  44% 2.18G/4.97G [00:40<00:29, 94.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  44% 2.20G/4.97G [00:41<00:31, 87.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.01G/2.67G [00:41<00:05, 114MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  45% 2.24G/4.97G [00:41<00:37, 73.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  45% 2.25G/4.97G [00:42<00:39, 69.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  46% 2.26G/4.97G [00:42<00:37, 71.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  46% 2.31G/4.97G [00:42<00:31, 85.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  48% 2.38G/4.97G [00:42<00:21, 122MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  48% 2.41G/4.97G [00:43<00:19, 130MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  50% 2.48G/4.97G [00:43<00:15, 161MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.08G/2.67G [00:43<00:10, 58.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 2.14G/2.67G [00:43<00:07, 74.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  51% 2.54G/4.97G [00:43<00:16, 147MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  53% 2.62G/4.97G [00:44<00:13, 170MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 2.19G/2.67G [00:44<00:06, 78.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  54% 2.70G/4.97G [00:44<00:11, 190MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 2.26G/2.67G [00:45<00:04, 86.4MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  56% 2.78G/4.97G [00:45<00:12, 173MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  57% 2.85G/4.97G [00:45<00:11, 186MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 2.30G/2.67G [00:45<00:04, 81.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  58% 2.90G/4.97G [00:45<00:11, 173MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  59% 2.92G/4.97G [00:46<00:14, 145MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  60% 2.97G/4.97G [00:46<00:14, 143MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  60% 3.00G/4.97G [00:47<00:18, 109MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 2.36G/2.67G [00:47<00:04, 64.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  62% 3.09G/4.97G [00:47<00:12, 152MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  63% 3.12G/4.97G [00:47<00:13, 142MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  63% 3.15G/4.97G [00:47<00:11, 160MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 2.43G/2.67G [00:47<00:03, 69.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  65% 3.21G/4.97G [00:47<00:09, 193MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  65% 3.25G/4.97G [00:48<00:11, 153MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  66% 3.29G/4.97G [00:48<00:09, 175MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  67% 3.35G/4.97G [00:48<00:08, 198MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  69% 3.41G/4.97G [00:48<00:06, 225MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  70% 3.48G/4.97G [00:49<00:06, 244MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  71% 3.55G/4.97G [00:49<00:05, 253MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  72% 3.60G/4.97G [00:49<00:06, 198MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  74% 3.67G/4.97G [00:49<00:05, 256MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 2.49G/2.67G [00:50<00:04, 45.4MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  75% 3.74G/4.97G [00:50<00:06, 187MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  77% 3.82G/4.97G [00:50<00:04, 256MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  78% 3.87G/4.97G [00:50<00:04, 250MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  79% 3.93G/4.97G [00:51<00:04, 234MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  80% 3.99G/4.97G [00:51<00:03, 275MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  81% 4.04G/4.97G [00:51<00:03, 273MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  82% 4.09G/4.97G [00:51<00:03, 267MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  83% 4.14G/4.97G [00:51<00:03, 249MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  85% 4.21G/4.97G [00:54<00:11, 68.1MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 2.54G/2.67G [00:54<00:04, 27.0MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  85% 4.25G/4.97G [00:54<00:10, 71.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  86% 4.30G/4.97G [00:54<00:07, 89.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  88% 4.36G/4.97G [00:55<00:05, 112MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  89% 4.43G/4.97G [00:55<00:03, 149MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  90% 4.49G/4.97G [00:55<00:03, 154MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  92% 4.56G/4.97G [00:55<00:02, 204MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  93% 4.62G/4.97G [00:55<00:01, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  94% 4.68G/4.97G [00:56<00:01, 208MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 2.60G/2.67G [00:56<00:02, 27.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  95% 4.75G/4.97G [00:56<00:01, 222MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  97% 4.81G/4.97G [00:56<00:00, 231MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  98% 4.86G/4.97G [00:57<00:00, 236MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  99% 4.91G/4.97G [00:57<00:00, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors: 100% 4.97G/4.97G [00:57<00:00, 86.3MB/s]\n",
            "Fetching 2 files:  50% 1/2 [00:58<00:58, 58.34s/it]\n",
            "model-00002-of-00002.safetensors: 100% 2.67G/2.67G [00:57<00:00, 46.2MB/s]\n",
            "Fetching 2 files: 100% 2/2 [00:58<00:00, 29.27s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:31<00:00, 15.72s/it]\n",
            "generation_config.json: 100% 181/181 [00:00<00:00, 1.88MB/s]\n",
            "Truncating train dataset: 100% 800/800 [00:00<00:00, 21558.86 examples/s]\n",
            "Truncating eval dataset: 100% 100/100 [00:00<00:00, 16132.56 examples/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mharithanallamilli1606\u001b[0m (\u001b[33mharithanallamilli1606-patnr-network\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m setting up run wdgee7pa (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m setting up run wdgee7pa (0.3s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/LLM-phi3-lora-finetuning/wandb/run-20260115_034957-wdgee7pa\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msilver-sponge-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/harithanallamilli1606-patnr-network/llm-phi3-lora-finetune-colab\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/harithanallamilli1606-patnr-network/llm-phi3-lora-finetune-colab/runs/wdgee7pa\u001b[0m\n",
            "  0% 3/1200 [00:40<4:27:10, 13.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 10.6905, 'grad_norm': 21.625, 'learning_rate': 0.00019850000000000003, 'entropy': 7.823828125, 'num_tokens': 20480.0, 'mean_token_accuracy': 0.0065493646543473005, 'epoch': 0.03}\n",
            "{'loss': 6.1328, 'grad_norm': 15.375, 'learning_rate': 0.00019683333333333334, 'entropy': 6.34921875, 'num_tokens': 40960.0, 'mean_token_accuracy': 0.007771261036396027, 'epoch': 0.05}\n",
            "{'loss': 1.5965, 'grad_norm': 25.375, 'learning_rate': 0.00019516666666666668, 'entropy': 1.1239501953125, 'num_tokens': 61440.0, 'mean_token_accuracy': 0.9186705827713013, 'epoch': 0.07}\n",
            "{'loss': 1.6544, 'grad_norm': 8.625, 'learning_rate': 0.00019350000000000001, 'entropy': 0.169696044921875, 'num_tokens': 81920.0, 'mean_token_accuracy': 0.9122189700603485, 'epoch': 0.1}\n",
            "{'loss': 0.9767, 'grad_norm': 8.3125, 'learning_rate': 0.00019183333333333333, 'entropy': 0.22242431640625, 'num_tokens': 102400.0, 'mean_token_accuracy': 0.9291300117969513, 'epoch': 0.12}\n",
            "{'loss': 0.5342, 'grad_norm': 1.078125, 'learning_rate': 0.00019016666666666666, 'entropy': 0.29501953125, 'num_tokens': 122880.0, 'mean_token_accuracy': 0.9419354856014251, 'epoch': 0.15}\n",
            "{'loss': 0.3776, 'grad_norm': 0.78515625, 'learning_rate': 0.0001885, 'entropy': 0.31553955078125, 'num_tokens': 143360.0, 'mean_token_accuracy': 0.9547898292541503, 'epoch': 0.17}\n",
            "{'loss': 0.3524, 'grad_norm': 1.078125, 'learning_rate': 0.00018683333333333334, 'entropy': 0.21690673828125, 'num_tokens': 163840.0, 'mean_token_accuracy': 0.9507820010185242, 'epoch': 0.2}\n",
            "{'loss': 0.2809, 'grad_norm': 0.80859375, 'learning_rate': 0.00018516666666666668, 'entropy': 0.22376708984375, 'num_tokens': 184320.0, 'mean_token_accuracy': 0.9579667508602142, 'epoch': 0.23}\n",
            "{'loss': 0.2067, 'grad_norm': 0.3984375, 'learning_rate': 0.00018350000000000002, 'entropy': 0.16702880859375, 'num_tokens': 204800.0, 'mean_token_accuracy': 0.9743890643119812, 'epoch': 0.25}\n",
            "{'loss': 0.2165, 'grad_norm': 0.5703125, 'learning_rate': 0.00018183333333333335, 'entropy': 0.17001953125, 'num_tokens': 225280.0, 'mean_token_accuracy': 0.9739491760730743, 'epoch': 0.28}\n",
            "{'loss': 0.2034, 'grad_norm': 0.287109375, 'learning_rate': 0.0001801666666666667, 'entropy': 0.18726806640625, 'num_tokens': 245760.0, 'mean_token_accuracy': 0.9731671631336212, 'epoch': 0.3}\n",
            "{'loss': 0.16, 'grad_norm': 0.197265625, 'learning_rate': 0.0001785, 'entropy': 0.13477783203125, 'num_tokens': 266240.0, 'mean_token_accuracy': 0.9827957153320312, 'epoch': 0.33}\n",
            "{'loss': 0.1519, 'grad_norm': 0.5703125, 'learning_rate': 0.00017683333333333334, 'entropy': 0.128680419921875, 'num_tokens': 286720.0, 'mean_token_accuracy': 0.9833333492279053, 'epoch': 0.35}\n",
            "{'loss': 0.1302, 'grad_norm': 1.46875, 'learning_rate': 0.00017516666666666668, 'entropy': 0.10352783203125, 'num_tokens': 307200.0, 'mean_token_accuracy': 0.9867057800292969, 'epoch': 0.38}\n",
            "{'loss': 0.1363, 'grad_norm': 0.4921875, 'learning_rate': 0.00017350000000000002, 'entropy': 0.111737060546875, 'num_tokens': 327680.0, 'mean_token_accuracy': 0.9830400943756104, 'epoch': 0.4}\n",
            "{'loss': 0.1255, 'grad_norm': 0.55078125, 'learning_rate': 0.00017183333333333333, 'entropy': 0.106134033203125, 'num_tokens': 348160.0, 'mean_token_accuracy': 0.9846041202545166, 'epoch': 0.42}\n",
            "{'loss': 0.1051, 'grad_norm': 0.5390625, 'learning_rate': 0.00017016666666666666, 'entropy': 0.09703369140625, 'num_tokens': 368640.0, 'mean_token_accuracy': 0.9887096881866455, 'epoch': 0.45}\n",
            "{'loss': 0.1061, 'grad_norm': 0.259765625, 'learning_rate': 0.0001685, 'entropy': 0.097442626953125, 'num_tokens': 389120.0, 'mean_token_accuracy': 0.9884164333343506, 'epoch': 0.47}\n",
            "{'loss': 0.1012, 'grad_norm': 0.83203125, 'learning_rate': 0.00016683333333333334, 'entropy': 0.08812255859375, 'num_tokens': 409600.0, 'mean_token_accuracy': 0.9890029430389404, 'epoch': 0.5}\n",
            "{'loss': 0.0966, 'grad_norm': 1.046875, 'learning_rate': 0.00016516666666666668, 'entropy': 0.082257080078125, 'num_tokens': 430080.0, 'mean_token_accuracy': 0.9887585639953613, 'epoch': 0.53}\n",
            "{'loss': 0.0904, 'grad_norm': 1.0078125, 'learning_rate': 0.00016350000000000002, 'entropy': 0.0989013671875, 'num_tokens': 450560.0, 'mean_token_accuracy': 0.9892473220825195, 'epoch': 0.55}\n",
            "{'loss': 0.0877, 'grad_norm': 0.32421875, 'learning_rate': 0.00016183333333333335, 'entropy': 0.10733642578125, 'num_tokens': 471040.0, 'mean_token_accuracy': 0.9893450736999512, 'epoch': 0.57}\n",
            "{'loss': 0.0765, 'grad_norm': 0.447265625, 'learning_rate': 0.00016016666666666667, 'entropy': 0.0971771240234375, 'num_tokens': 491520.0, 'mean_token_accuracy': 0.9889540672302246, 'epoch': 0.6}\n",
            "{'loss': 0.065, 'grad_norm': 0.478515625, 'learning_rate': 0.0001585, 'entropy': 0.1136505126953125, 'num_tokens': 512000.0, 'mean_token_accuracy': 0.9900782108306885, 'epoch': 0.62}\n",
            "{'loss': 0.0561, 'grad_norm': 0.1982421875, 'learning_rate': 0.00015683333333333334, 'entropy': 0.0879302978515625, 'num_tokens': 532480.0, 'mean_token_accuracy': 0.9907135963439941, 'epoch': 0.65}\n",
            "{'loss': 0.0513, 'grad_norm': 0.33203125, 'learning_rate': 0.00015516666666666668, 'entropy': 0.089141845703125, 'num_tokens': 552960.0, 'mean_token_accuracy': 0.9910068511962891, 'epoch': 0.68}\n",
            "{'loss': 0.0487, 'grad_norm': 0.2412109375, 'learning_rate': 0.0001535, 'entropy': 0.08387451171875, 'num_tokens': 573440.0, 'mean_token_accuracy': 0.9907135963439941, 'epoch': 0.7}\n",
            "{'loss': 0.0449, 'grad_norm': 0.20703125, 'learning_rate': 0.00015183333333333333, 'entropy': 0.0738037109375, 'num_tokens': 593920.0, 'mean_token_accuracy': 0.9898338317871094, 'epoch': 0.72}\n",
            "{'loss': 0.0428, 'grad_norm': 0.376953125, 'learning_rate': 0.00015016666666666667, 'entropy': 0.074658203125, 'num_tokens': 614400.0, 'mean_token_accuracy': 0.9897849559783936, 'epoch': 0.75}\n",
            "{'loss': 0.0411, 'grad_norm': 0.255859375, 'learning_rate': 0.0001485, 'entropy': 0.077215576171875, 'num_tokens': 634880.0, 'mean_token_accuracy': 0.9897360801696777, 'epoch': 0.78}\n",
            "{'loss': 0.0404, 'grad_norm': 0.6953125, 'learning_rate': 0.00014683333333333334, 'entropy': 0.07901611328125, 'num_tokens': 655360.0, 'mean_token_accuracy': 0.989931583404541, 'epoch': 0.8}\n",
            "{'loss': 0.0404, 'grad_norm': 1.8515625, 'learning_rate': 0.00014516666666666668, 'entropy': 0.083062744140625, 'num_tokens': 675840.0, 'mean_token_accuracy': 0.9905180931091309, 'epoch': 0.82}\n",
            "{'loss': 0.0397, 'grad_norm': 0.26953125, 'learning_rate': 0.00014350000000000002, 'entropy': 0.08787841796875, 'num_tokens': 696320.0, 'mean_token_accuracy': 0.991300106048584, 'epoch': 0.85}\n",
            "{'loss': 0.0394, 'grad_norm': 0.26953125, 'learning_rate': 0.00014183333333333333, 'entropy': 0.090863037109375, 'num_tokens': 716800.0, 'mean_token_accuracy': 0.991300106048584, 'epoch': 0.88}\n",
            "{'loss': 0.0393, 'grad_norm': 0.2333984375, 'learning_rate': 0.00014016666666666667, 'entropy': 0.097540283203125, 'num_tokens': 737280.0, 'mean_token_accuracy': 0.9919843673706055, 'epoch': 0.9}\n",
            "{'loss': 0.0403, 'grad_norm': 0.380859375, 'learning_rate': 0.0001385, 'entropy': 0.0977783203125, 'num_tokens': 757760.0, 'mean_token_accuracy': 0.9914467334747314, 'epoch': 0.93}\n",
            "{'loss': 0.0405, 'grad_norm': 0.72265625, 'learning_rate': 0.00013683333333333334, 'entropy': 0.091748046875, 'num_tokens': 778240.0, 'mean_token_accuracy': 0.9910068511962891, 'epoch': 0.95}\n",
            "{'loss': 0.0423, 'grad_norm': 0.69140625, 'learning_rate': 0.00013516666666666665, 'entropy': 0.10078125, 'num_tokens': 798720.0, 'mean_token_accuracy': 0.9920332431793213, 'epoch': 0.97}\n",
            "{'loss': 0.0431, 'grad_norm': 0.8046875, 'learning_rate': 0.0001335, 'entropy': 0.110772705078125, 'num_tokens': 819200.0, 'mean_token_accuracy': 0.9920332431793213, 'epoch': 1.0}\n",
            " 33% 400/1200 [1:33:09<3:05:56, 13.95s/it]\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:06<02:24,  3.02s/it]\u001b[A\n",
            "  6% 3/50 [00:12<03:21,  4.29s/it]\u001b[A\n",
            "  8% 4/50 [00:18<03:47,  4.95s/it]\u001b[A\n",
            " 10% 5/50 [00:24<03:59,  5.33s/it]\u001b[A\n",
            " 12% 6/50 [00:30<04:05,  5.58s/it]\u001b[A\n",
            " 14% 7/50 [00:36<04:06,  5.73s/it]\u001b[A\n",
            " 16% 8/50 [00:42<04:05,  5.83s/it]\u001b[A\n",
            " 18% 9/50 [00:48<04:02,  5.91s/it]\u001b[A\n",
            " 20% 10/50 [00:54<03:58,  5.96s/it]\u001b[A\n",
            " 22% 11/50 [01:00<03:53,  5.99s/it]\u001b[A\n",
            " 24% 12/50 [01:06<03:48,  6.01s/it]\u001b[A\n",
            " 26% 13/50 [01:12<03:42,  6.02s/it]\u001b[A\n",
            " 28% 14/50 [01:18<03:37,  6.04s/it]\u001b[A\n",
            " 30% 15/50 [01:24<03:31,  6.04s/it]\u001b[A\n",
            " 32% 16/50 [01:30<03:25,  6.05s/it]\u001b[A\n",
            " 34% 17/50 [01:36<03:19,  6.04s/it]\u001b[A\n",
            " 36% 18/50 [01:42<03:13,  6.04s/it]\u001b[A\n",
            " 38% 19/50 [01:49<03:07,  6.04s/it]\u001b[A\n",
            " 40% 20/50 [01:55<03:01,  6.05s/it]\u001b[A\n",
            " 42% 21/50 [02:01<02:55,  6.05s/it]\u001b[A\n",
            " 44% 22/50 [02:07<02:49,  6.05s/it]\u001b[A\n",
            " 46% 23/50 [02:13<02:43,  6.05s/it]\u001b[A\n",
            " 48% 24/50 [02:19<02:37,  6.04s/it]\u001b[A\n",
            " 50% 25/50 [02:25<02:30,  6.04s/it]\u001b[A\n",
            " 52% 26/50 [02:31<02:25,  6.04s/it]\u001b[A\n",
            " 54% 27/50 [02:37<02:18,  6.04s/it]\u001b[A\n",
            " 56% 28/50 [02:43<02:12,  6.04s/it]\u001b[A\n",
            " 58% 29/50 [02:49<02:06,  6.04s/it]\u001b[A\n",
            " 60% 30/50 [02:55<02:00,  6.05s/it]\u001b[A\n",
            " 62% 31/50 [03:01<01:54,  6.05s/it]\u001b[A\n",
            " 64% 32/50 [03:07<01:48,  6.05s/it]\u001b[A\n",
            " 66% 33/50 [03:13<01:42,  6.05s/it]\u001b[A\n",
            " 68% 34/50 [03:19<01:36,  6.05s/it]\u001b[A\n",
            " 70% 35/50 [03:25<01:30,  6.05s/it]\u001b[A\n",
            " 72% 36/50 [03:31<01:24,  6.04s/it]\u001b[A\n",
            " 74% 37/50 [03:37<01:18,  6.05s/it]\u001b[A\n",
            " 76% 38/50 [03:43<01:12,  6.05s/it]\u001b[A\n",
            " 78% 39/50 [03:49<01:06,  6.05s/it]\u001b[A\n",
            " 80% 40/50 [03:55<01:00,  6.05s/it]\u001b[A\n",
            " 82% 41/50 [04:02<00:54,  6.05s/it]\u001b[A\n",
            " 84% 42/50 [04:08<00:48,  6.05s/it]\u001b[A\n",
            " 86% 43/50 [04:14<00:42,  6.05s/it]\u001b[A\n",
            " 88% 44/50 [04:20<00:36,  6.04s/it]\u001b[A\n",
            " 90% 45/50 [04:26<00:30,  6.04s/it]\u001b[A\n",
            " 92% 46/50 [04:32<00:24,  6.04s/it]\u001b[A\n",
            " 94% 47/50 [04:38<00:18,  6.04s/it]\u001b[A\n",
            " 96% 48/50 [04:44<00:12,  6.04s/it]\u001b[A\n",
            " 98% 49/50 [04:50<00:06,  6.04s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.04404890164732933, 'eval_runtime': 302.48, 'eval_samples_per_second': 0.331, 'eval_steps_per_second': 0.165, 'eval_entropy': 0.10894287109375, 'eval_num_tokens': 819200.0, 'eval_mean_token_accuracy': 0.9902541637420654, 'epoch': 1.0}\n",
            " 33% 400/1200 [1:38:11<3:05:56, 13.95s/it]\n",
            "100% 50/50 [04:56<00:00,  6.04s/it]\u001b[A\n",
            "{'loss': 0.0441, 'grad_norm': 0.458984375, 'learning_rate': 0.00013183333333333333, 'entropy': 0.119512939453125, 'num_tokens': 839680.0, 'mean_token_accuracy': 0.9914956092834473, 'epoch': 1.02}\n",
            "{'loss': 0.0431, 'grad_norm': 0.291015625, 'learning_rate': 0.00013016666666666667, 'entropy': 0.108721923828125, 'num_tokens': 860160.0, 'mean_token_accuracy': 0.9913978576660156, 'epoch': 1.05}\n",
            "{'loss': 0.0516, 'grad_norm': 1.9296875, 'learning_rate': 0.0001285, 'entropy': 0.15374755859375, 'num_tokens': 880640.0, 'mean_token_accuracy': 0.9896383285522461, 'epoch': 1.07}\n",
            "{'loss': 0.126, 'grad_norm': 9.375, 'learning_rate': 0.00012683333333333334, 'entropy': 0.10045928955078125, 'num_tokens': 901120.0, 'mean_token_accuracy': 0.9866080284118652, 'epoch': 1.1}\n",
            "{'loss': 0.2057, 'grad_norm': 4.0, 'learning_rate': 0.00012516666666666668, 'entropy': 0.031438446044921874, 'num_tokens': 921600.0, 'mean_token_accuracy': 0.9831867218017578, 'epoch': 1.12}\n",
            "{'loss': 0.1421, 'grad_norm': 2.5625, 'learning_rate': 0.00012350000000000002, 'entropy': 0.0688720703125, 'num_tokens': 942080.0, 'mean_token_accuracy': 0.9875366687774658, 'epoch': 1.15}\n",
            "{'loss': 0.1128, 'grad_norm': 0.76953125, 'learning_rate': 0.00012183333333333333, 'entropy': 0.1874298095703125, 'num_tokens': 962560.0, 'mean_token_accuracy': 0.9889051914215088, 'epoch': 1.18}\n",
            "{'loss': 0.0965, 'grad_norm': 1.3515625, 'learning_rate': 0.00012016666666666667, 'entropy': 0.177484130859375, 'num_tokens': 983040.0, 'mean_token_accuracy': 0.9888074398040771, 'epoch': 1.2}\n",
            "{'loss': 0.0866, 'grad_norm': 0.5078125, 'learning_rate': 0.00011850000000000001, 'entropy': 0.1879638671875, 'num_tokens': 1003520.0, 'mean_token_accuracy': 0.9898338317871094, 'epoch': 1.23}\n",
            "{'loss': 0.0771, 'grad_norm': 9.3125, 'learning_rate': 0.00011683333333333333, 'entropy': 0.17105712890625, 'num_tokens': 1024000.0, 'mean_token_accuracy': 0.9891984462738037, 'epoch': 1.25}\n",
            "{'loss': 0.069, 'grad_norm': 1.7890625, 'learning_rate': 0.00011516666666666667, 'entropy': 0.18798828125, 'num_tokens': 1044480.0, 'mean_token_accuracy': 0.9897360801696777, 'epoch': 1.27}\n",
            "{'loss': 0.0675, 'grad_norm': 0.82421875, 'learning_rate': 0.00011350000000000001, 'entropy': 0.220458984375, 'num_tokens': 1064960.0, 'mean_token_accuracy': 0.9895894527435303, 'epoch': 1.3}\n",
            "{'loss': 0.0629, 'grad_norm': 0.64453125, 'learning_rate': 0.00011183333333333335, 'entropy': 0.1968994140625, 'num_tokens': 1085440.0, 'mean_token_accuracy': 0.9893450736999512, 'epoch': 1.32}\n",
            "{'loss': 0.0652, 'grad_norm': 0.80078125, 'learning_rate': 0.00011016666666666666, 'entropy': 0.20924072265625, 'num_tokens': 1105920.0, 'mean_token_accuracy': 0.9882698059082031, 'epoch': 1.35}\n",
            "{'loss': 0.0602, 'grad_norm': 0.83984375, 'learning_rate': 0.00010850000000000001, 'entropy': 0.20667724609375, 'num_tokens': 1126400.0, 'mean_token_accuracy': 0.9897849559783936, 'epoch': 1.38}\n",
            "{'loss': 0.0639, 'grad_norm': 0.8671875, 'learning_rate': 0.00010683333333333335, 'entropy': 0.22447509765625, 'num_tokens': 1146880.0, 'mean_token_accuracy': 0.9888074398040771, 'epoch': 1.4}\n",
            "{'loss': 0.061, 'grad_norm': 1.234375, 'learning_rate': 0.00010516666666666668, 'entropy': 0.2120361328125, 'num_tokens': 1167360.0, 'mean_token_accuracy': 0.9894428253173828, 'epoch': 1.43}\n",
            "{'loss': 0.0592, 'grad_norm': 0.296875, 'learning_rate': 0.0001035, 'entropy': 0.22030029296875, 'num_tokens': 1187840.0, 'mean_token_accuracy': 0.9908113479614258, 'epoch': 1.45}\n",
            "{'loss': 0.0573, 'grad_norm': 0.8046875, 'learning_rate': 0.00010183333333333333, 'entropy': 0.2192138671875, 'num_tokens': 1208320.0, 'mean_token_accuracy': 0.9912023544311523, 'epoch': 1.48}\n",
            "{'loss': 0.0596, 'grad_norm': 1.53125, 'learning_rate': 0.00010016666666666667, 'entropy': 0.22733154296875, 'num_tokens': 1228800.0, 'mean_token_accuracy': 0.9901759624481201, 'epoch': 1.5}\n",
            "{'loss': 0.0599, 'grad_norm': 1.03125, 'learning_rate': 9.850000000000001e-05, 'entropy': 0.2320068359375, 'num_tokens': 1249280.0, 'mean_token_accuracy': 0.9904203414916992, 'epoch': 1.52}\n",
            "{'loss': 0.0604, 'grad_norm': 1.28125, 'learning_rate': 9.683333333333335e-05, 'entropy': 0.2369873046875, 'num_tokens': 1269760.0, 'mean_token_accuracy': 0.9906647205352783, 'epoch': 1.55}\n",
            "{'loss': 0.0606, 'grad_norm': 0.494140625, 'learning_rate': 9.516666666666667e-05, 'entropy': 0.2397705078125, 'num_tokens': 1290240.0, 'mean_token_accuracy': 0.9912023544311523, 'epoch': 1.57}\n",
            "{'loss': 0.0633, 'grad_norm': 0.890625, 'learning_rate': 9.350000000000001e-05, 'entropy': 0.2578125, 'num_tokens': 1310720.0, 'mean_token_accuracy': 0.9909579753875732, 'epoch': 1.6}\n",
            "{'loss': 0.0603, 'grad_norm': 1.7890625, 'learning_rate': 9.183333333333333e-05, 'entropy': 0.2481201171875, 'num_tokens': 1331200.0, 'mean_token_accuracy': 0.9918866157531738, 'epoch': 1.62}\n",
            "{'loss': 0.0602, 'grad_norm': 0.8359375, 'learning_rate': 9.016666666666667e-05, 'entropy': 0.24925537109375, 'num_tokens': 1351680.0, 'mean_token_accuracy': 0.9916911125183105, 'epoch': 1.65}\n",
            "{'loss': 0.0604, 'grad_norm': 0.515625, 'learning_rate': 8.850000000000001e-05, 'entropy': 0.2487548828125, 'num_tokens': 1372160.0, 'mean_token_accuracy': 0.9914956092834473, 'epoch': 1.68}\n",
            "{'loss': 0.0605, 'grad_norm': 2.140625, 'learning_rate': 8.683333333333333e-05, 'entropy': 0.2513671875, 'num_tokens': 1392640.0, 'mean_token_accuracy': 0.9910557270050049, 'epoch': 1.7}\n",
            "{'loss': 0.0605, 'grad_norm': 1.1171875, 'learning_rate': 8.516666666666667e-05, 'entropy': 0.24993896484375, 'num_tokens': 1413120.0, 'mean_token_accuracy': 0.9909090995788574, 'epoch': 1.73}\n",
            "{'loss': 0.0607, 'grad_norm': 0.6484375, 'learning_rate': 8.35e-05, 'entropy': 0.25186767578125, 'num_tokens': 1433600.0, 'mean_token_accuracy': 0.991300106048584, 'epoch': 1.75}\n",
            "{'loss': 0.0635, 'grad_norm': 0.70703125, 'learning_rate': 8.183333333333333e-05, 'entropy': 0.264892578125, 'num_tokens': 1454080.0, 'mean_token_accuracy': 0.9914467334747314, 'epoch': 1.77}\n",
            "{'loss': 0.0655, 'grad_norm': 6.46875, 'learning_rate': 8.016666666666667e-05, 'entropy': 0.26392822265625, 'num_tokens': 1474560.0, 'mean_token_accuracy': 0.9910068511962891, 'epoch': 1.8}\n",
            "{'loss': 0.0653, 'grad_norm': 0.97265625, 'learning_rate': 7.850000000000001e-05, 'entropy': 0.2716552734375, 'num_tokens': 1495040.0, 'mean_token_accuracy': 0.9913489818572998, 'epoch': 1.82}\n",
            "{'loss': 0.066, 'grad_norm': 0.7890625, 'learning_rate': 7.683333333333334e-05, 'entropy': 0.27275390625, 'num_tokens': 1515520.0, 'mean_token_accuracy': 0.9905669689178467, 'epoch': 1.85}\n",
            "{'loss': 0.0658, 'grad_norm': 1.109375, 'learning_rate': 7.516666666666667e-05, 'entropy': 0.277197265625, 'num_tokens': 1536000.0, 'mean_token_accuracy': 0.9913978576660156, 'epoch': 1.88}\n",
            "{'loss': 0.0663, 'grad_norm': 1.1796875, 'learning_rate': 7.35e-05, 'entropy': 0.2782958984375, 'num_tokens': 1556480.0, 'mean_token_accuracy': 0.9907135963439941, 'epoch': 1.9}\n",
            "{'loss': 0.0653, 'grad_norm': 1.671875, 'learning_rate': 7.183333333333334e-05, 'entropy': 0.2721923828125, 'num_tokens': 1576960.0, 'mean_token_accuracy': 0.990469217300415, 'epoch': 1.93}\n",
            "{'loss': 0.0675, 'grad_norm': 0.8359375, 'learning_rate': 7.016666666666667e-05, 'entropy': 0.2856689453125, 'num_tokens': 1597440.0, 'mean_token_accuracy': 0.9910557270050049, 'epoch': 1.95}\n",
            "{'loss': 0.0683, 'grad_norm': 1.671875, 'learning_rate': 6.850000000000001e-05, 'entropy': 0.28837890625, 'num_tokens': 1617920.0, 'mean_token_accuracy': 0.9909090995788574, 'epoch': 1.98}\n",
            "{'loss': 0.0673, 'grad_norm': 1.375, 'learning_rate': 6.683333333333334e-05, 'entropy': 0.2837646484375, 'num_tokens': 1638400.0, 'mean_token_accuracy': 0.9908113479614258, 'epoch': 2.0}\n",
            " 67% 800/1200 [3:11:04<1:33:23, 14.01s/it]\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:06<02:25,  3.02s/it]\u001b[A\n",
            "  6% 3/50 [00:12<03:21,  4.29s/it]\u001b[A\n",
            "  8% 4/50 [00:18<03:47,  4.95s/it]\u001b[A\n",
            " 10% 5/50 [00:24<03:59,  5.33s/it]\u001b[A\n",
            " 12% 6/50 [00:30<04:05,  5.58s/it]\u001b[A\n",
            " 14% 7/50 [00:36<04:06,  5.74s/it]\u001b[A\n",
            " 16% 8/50 [00:42<04:05,  5.84s/it]\u001b[A\n",
            " 18% 9/50 [00:48<04:02,  5.92s/it]\u001b[A\n",
            " 20% 10/50 [00:54<03:58,  5.97s/it]\u001b[A\n",
            " 22% 11/50 [01:00<03:54,  6.00s/it]\u001b[A\n",
            " 24% 12/50 [01:06<03:48,  6.02s/it]\u001b[A\n",
            " 26% 13/50 [01:12<03:43,  6.04s/it]\u001b[A\n",
            " 28% 14/50 [01:18<03:37,  6.05s/it]\u001b[A\n",
            " 30% 15/50 [01:24<03:31,  6.05s/it]\u001b[A\n",
            " 32% 16/50 [01:31<03:25,  6.06s/it]\u001b[A\n",
            " 34% 17/50 [01:37<03:20,  6.06s/it]\u001b[A\n",
            " 36% 18/50 [01:43<03:13,  6.06s/it]\u001b[A\n",
            " 38% 19/50 [01:49<03:07,  6.06s/it]\u001b[A\n",
            " 40% 20/50 [01:55<03:01,  6.06s/it]\u001b[A\n",
            " 42% 21/50 [02:01<02:55,  6.07s/it]\u001b[A\n",
            " 44% 22/50 [02:07<02:49,  6.07s/it]\u001b[A\n",
            " 46% 23/50 [02:13<02:43,  6.07s/it]\u001b[A\n",
            " 48% 24/50 [02:19<02:37,  6.07s/it]\u001b[A\n",
            " 50% 25/50 [02:25<02:31,  6.07s/it]\u001b[A\n",
            " 52% 26/50 [02:31<02:25,  6.08s/it]\u001b[A\n",
            " 54% 27/50 [02:37<02:19,  6.07s/it]\u001b[A\n",
            " 56% 28/50 [02:43<02:13,  6.07s/it]\u001b[A\n",
            " 58% 29/50 [02:49<02:07,  6.07s/it]\u001b[A\n",
            " 60% 30/50 [02:56<02:01,  6.07s/it]\u001b[A\n",
            " 62% 31/50 [03:02<01:55,  6.07s/it]\u001b[A\n",
            " 64% 32/50 [03:08<01:49,  6.07s/it]\u001b[A\n",
            " 66% 33/50 [03:14<01:43,  6.07s/it]\u001b[A\n",
            " 68% 34/50 [03:20<01:36,  6.06s/it]\u001b[A\n",
            " 70% 35/50 [03:26<01:30,  6.06s/it]\u001b[A\n",
            " 72% 36/50 [03:32<01:24,  6.05s/it]\u001b[A\n",
            " 74% 37/50 [03:38<01:18,  6.05s/it]\u001b[A\n",
            " 76% 38/50 [03:44<01:12,  6.05s/it]\u001b[A\n",
            " 78% 39/50 [03:50<01:06,  6.05s/it]\u001b[A\n",
            " 80% 40/50 [03:56<01:00,  6.04s/it]\u001b[A\n",
            " 82% 41/50 [04:02<00:54,  6.04s/it]\u001b[A\n",
            " 84% 42/50 [04:08<00:48,  6.04s/it]\u001b[A\n",
            " 86% 43/50 [04:14<00:42,  6.04s/it]\u001b[A\n",
            " 88% 44/50 [04:20<00:36,  6.04s/it]\u001b[A\n",
            " 90% 45/50 [04:26<00:30,  6.03s/it]\u001b[A\n",
            " 92% 46/50 [04:32<00:24,  6.04s/it]\u001b[A\n",
            " 94% 47/50 [04:38<00:18,  6.03s/it]\u001b[A\n",
            " 96% 48/50 [04:44<00:12,  6.03s/it]\u001b[A\n",
            " 98% 49/50 [04:50<00:06,  6.03s/it]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.06888484954833984, 'eval_runtime': 302.9417, 'eval_samples_per_second': 0.33, 'eval_steps_per_second': 0.165, 'eval_entropy': 0.2938818359375, 'eval_num_tokens': 1638400.0, 'eval_mean_token_accuracy': 0.9909775257110596, 'epoch': 2.0}\n",
            " 67% 800/1200 [3:16:07<1:33:23, 14.01s/it]\n",
            "100% 50/50 [04:56<00:00,  6.04s/it]\u001b[A\n",
            "{'loss': 0.0671, 'grad_norm': 1.15625, 'learning_rate': 6.516666666666666e-05, 'entropy': 0.283447265625, 'num_tokens': 1658880.0, 'mean_token_accuracy': 0.9908602237701416, 'epoch': 2.02}\n",
            "{'loss': 0.0683, 'grad_norm': 1.46875, 'learning_rate': 6.35e-05, 'entropy': 0.289111328125, 'num_tokens': 1679360.0, 'mean_token_accuracy': 0.9908602237701416, 'epoch': 2.05}\n",
            "{'loss': 0.0673, 'grad_norm': 1.046875, 'learning_rate': 6.183333333333334e-05, 'entropy': 0.283544921875, 'num_tokens': 1699840.0, 'mean_token_accuracy': 0.9901270866394043, 'epoch': 2.08}\n",
            "{'loss': 0.0685, 'grad_norm': 1.6328125, 'learning_rate': 6.0166666666666674e-05, 'entropy': 0.28916015625, 'num_tokens': 1720320.0, 'mean_token_accuracy': 0.9906158447265625, 'epoch': 2.1}\n",
            "{'loss': 0.0698, 'grad_norm': 1.3828125, 'learning_rate': 5.85e-05, 'entropy': 0.295654296875, 'num_tokens': 1740800.0, 'mean_token_accuracy': 0.990469217300415, 'epoch': 2.12}\n",
            "{'loss': 0.0698, 'grad_norm': 1.296875, 'learning_rate': 5.683333333333334e-05, 'entropy': 0.296875, 'num_tokens': 1761280.0, 'mean_token_accuracy': 0.9909090995788574, 'epoch': 2.15}\n",
            "{'loss': 0.0667, 'grad_norm': 1.5546875, 'learning_rate': 5.516666666666667e-05, 'entropy': 0.280712890625, 'num_tokens': 1781760.0, 'mean_token_accuracy': 0.9907135963439941, 'epoch': 2.17}\n",
            "{'loss': 0.0712, 'grad_norm': 1.4140625, 'learning_rate': 5.3500000000000006e-05, 'entropy': 0.3025146484375, 'num_tokens': 1802240.0, 'mean_token_accuracy': 0.9913489818572998, 'epoch': 2.2}\n",
            "{'loss': 0.0687, 'grad_norm': 1.3828125, 'learning_rate': 5.183333333333333e-05, 'entropy': 0.294970703125, 'num_tokens': 1822720.0, 'mean_token_accuracy': 0.9915933609008789, 'epoch': 2.23}\n",
            "{'loss': 0.0695, 'grad_norm': 1.421875, 'learning_rate': 5.0166666666666675e-05, 'entropy': 0.296484375, 'num_tokens': 1843200.0, 'mean_token_accuracy': 0.991300106048584, 'epoch': 2.25}\n",
            "{'loss': 0.07, 'grad_norm': 1.5625, 'learning_rate': 4.85e-05, 'entropy': 0.2963623046875, 'num_tokens': 1863680.0, 'mean_token_accuracy': 0.9913489818572998, 'epoch': 2.27}\n",
            "{'loss': 0.0705, 'grad_norm': 1.8671875, 'learning_rate': 4.683333333333334e-05, 'entropy': 0.30029296875, 'num_tokens': 1884160.0, 'mean_token_accuracy': 0.9914467334747314, 'epoch': 2.3}\n",
            "{'loss': 0.0703, 'grad_norm': 1.5234375, 'learning_rate': 4.516666666666667e-05, 'entropy': 0.3, 'num_tokens': 1904640.0, 'mean_token_accuracy': 0.9915933609008789, 'epoch': 2.33}\n",
            "{'loss': 0.0694, 'grad_norm': 1.3828125, 'learning_rate': 4.35e-05, 'entropy': 0.293115234375, 'num_tokens': 1925120.0, 'mean_token_accuracy': 0.9907135963439941, 'epoch': 2.35}\n",
            "{'loss': 0.0704, 'grad_norm': 1.703125, 'learning_rate': 4.183333333333334e-05, 'entropy': 0.29814453125, 'num_tokens': 1945600.0, 'mean_token_accuracy': 0.990469217300415, 'epoch': 2.38}\n",
            "{'loss': 0.0711, 'grad_norm': 1.9921875, 'learning_rate': 4.016666666666667e-05, 'entropy': 0.3034912109375, 'num_tokens': 1966080.0, 'mean_token_accuracy': 0.9912023544311523, 'epoch': 2.4}\n",
            "{'loss': 0.0708, 'grad_norm': 1.6640625, 'learning_rate': 3.85e-05, 'entropy': 0.302294921875, 'num_tokens': 1986560.0, 'mean_token_accuracy': 0.9917399883270264, 'epoch': 2.42}\n",
            "{'loss': 0.0711, 'grad_norm': 1.8671875, 'learning_rate': 3.683333333333334e-05, 'entropy': 0.3020263671875, 'num_tokens': 2007040.0, 'mean_token_accuracy': 0.9917888641357422, 'epoch': 2.45}\n",
            "{'loss': 0.0709, 'grad_norm': 1.6796875, 'learning_rate': 3.516666666666667e-05, 'entropy': 0.301171875, 'num_tokens': 2027520.0, 'mean_token_accuracy': 0.9915933609008789, 'epoch': 2.48}\n",
            "{'loss': 0.0706, 'grad_norm': 1.5, 'learning_rate': 3.35e-05, 'entropy': 0.2992431640625, 'num_tokens': 2048000.0, 'mean_token_accuracy': 0.9911534786224365, 'epoch': 2.5}\n",
            "{'loss': 0.0696, 'grad_norm': 1.390625, 'learning_rate': 3.183333333333334e-05, 'entropy': 0.2942138671875, 'num_tokens': 2068480.0, 'mean_token_accuracy': 0.9911046028137207, 'epoch': 2.52}\n",
            "{'loss': 0.0688, 'grad_norm': 1.4140625, 'learning_rate': 3.016666666666667e-05, 'entropy': 0.290673828125, 'num_tokens': 2088960.0, 'mean_token_accuracy': 0.9912512302398682, 'epoch': 2.55}\n",
            "{'loss': 0.0703, 'grad_norm': 1.65625, 'learning_rate': 2.8499999999999998e-05, 'entropy': 0.2973876953125, 'num_tokens': 2109440.0, 'mean_token_accuracy': 0.9908113479614258, 'epoch': 2.58}\n",
            "{'loss': 0.0708, 'grad_norm': 1.6171875, 'learning_rate': 2.6833333333333333e-05, 'entropy': 0.3003662109375, 'num_tokens': 2129920.0, 'mean_token_accuracy': 0.99076247215271, 'epoch': 2.6}\n",
            "{'loss': 0.0719, 'grad_norm': 1.734375, 'learning_rate': 2.5166666666666667e-05, 'entropy': 0.3052001953125, 'num_tokens': 2150400.0, 'mean_token_accuracy': 0.9908113479614258, 'epoch': 2.62}\n",
            "{'loss': 0.0715, 'grad_norm': 1.7421875, 'learning_rate': 2.35e-05, 'entropy': 0.3034912109375, 'num_tokens': 2170880.0, 'mean_token_accuracy': 0.9911534786224365, 'epoch': 2.65}\n",
            "{'loss': 0.0716, 'grad_norm': 1.8515625, 'learning_rate': 2.1833333333333333e-05, 'entropy': 0.3051025390625, 'num_tokens': 2191360.0, 'mean_token_accuracy': 0.9911534786224365, 'epoch': 2.67}\n",
            "{'loss': 0.0721, 'grad_norm': 1.75, 'learning_rate': 2.0166666666666668e-05, 'entropy': 0.3069091796875, 'num_tokens': 2211840.0, 'mean_token_accuracy': 0.9912512302398682, 'epoch': 2.7}\n",
            "{'loss': 0.0716, 'grad_norm': 1.765625, 'learning_rate': 1.85e-05, 'entropy': 0.305126953125, 'num_tokens': 2232320.0, 'mean_token_accuracy': 0.9914467334747314, 'epoch': 2.73}\n",
            "{'loss': 0.0713, 'grad_norm': 1.6953125, 'learning_rate': 1.6833333333333334e-05, 'entropy': 0.301806640625, 'num_tokens': 2252800.0, 'mean_token_accuracy': 0.9908602237701416, 'epoch': 2.75}\n",
            "{'loss': 0.0723, 'grad_norm': 1.7734375, 'learning_rate': 1.5166666666666668e-05, 'entropy': 0.3061279296875, 'num_tokens': 2273280.0, 'mean_token_accuracy': 0.9909090995788574, 'epoch': 2.77}\n",
            "{'loss': 0.0723, 'grad_norm': 1.6953125, 'learning_rate': 1.3500000000000001e-05, 'entropy': 0.3078369140625, 'num_tokens': 2293760.0, 'mean_token_accuracy': 0.9908113479614258, 'epoch': 2.8}\n",
            "{'loss': 0.0717, 'grad_norm': 1.6640625, 'learning_rate': 1.1833333333333334e-05, 'entropy': 0.3048095703125, 'num_tokens': 2314240.0, 'mean_token_accuracy': 0.9910557270050049, 'epoch': 2.83}\n",
            "{'loss': 0.0715, 'grad_norm': 1.6796875, 'learning_rate': 1.0166666666666667e-05, 'entropy': 0.3038818359375, 'num_tokens': 2334720.0, 'mean_token_accuracy': 0.9908602237701416, 'epoch': 2.85}\n",
            "{'loss': 0.0713, 'grad_norm': 1.71875, 'learning_rate': 8.500000000000002e-06, 'entropy': 0.3044921875, 'num_tokens': 2355200.0, 'mean_token_accuracy': 0.9913489818572998, 'epoch': 2.88}\n",
            "{'loss': 0.0715, 'grad_norm': 1.7265625, 'learning_rate': 6.833333333333333e-06, 'entropy': 0.304931640625, 'num_tokens': 2375680.0, 'mean_token_accuracy': 0.991300106048584, 'epoch': 2.9}\n",
            "{'loss': 0.0712, 'grad_norm': 1.75, 'learning_rate': 5.166666666666667e-06, 'entropy': 0.30302734375, 'num_tokens': 2396160.0, 'mean_token_accuracy': 0.991300106048584, 'epoch': 2.92}\n",
            "{'loss': 0.0718, 'grad_norm': 1.7578125, 'learning_rate': 3.5000000000000004e-06, 'entropy': 0.30458984375, 'num_tokens': 2416640.0, 'mean_token_accuracy': 0.9910557270050049, 'epoch': 2.95}\n",
            "{'loss': 0.0715, 'grad_norm': 1.8046875, 'learning_rate': 1.8333333333333335e-06, 'entropy': 0.3026123046875, 'num_tokens': 2437120.0, 'mean_token_accuracy': 0.9908113479614258, 'epoch': 2.98}\n",
            "{'loss': 0.0722, 'grad_norm': 1.7578125, 'learning_rate': 1.6666666666666668e-07, 'entropy': 0.3081787109375, 'num_tokens': 2457600.0, 'mean_token_accuracy': 0.9910068511962891, 'epoch': 3.0}\n",
            "100% 1200/1200 [4:49:35<00:00, 14.02s/it]\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/50 [00:06<02:25,  3.02s/it]\u001b[A\n",
            "  6% 3/50 [00:12<03:21,  4.29s/it]\u001b[A\n",
            "  8% 4/50 [00:18<03:47,  4.95s/it]\u001b[A\n",
            " 10% 5/50 [00:24<03:59,  5.33s/it]\u001b[A\n",
            " 12% 6/50 [00:30<04:05,  5.58s/it]\u001b[A\n",
            " 14% 7/50 [00:36<04:06,  5.73s/it]\u001b[A\n",
            " 16% 8/50 [00:42<04:05,  5.83s/it]\u001b[A\n",
            " 18% 9/50 [00:48<04:02,  5.91s/it]\u001b[A\n",
            " 20% 10/50 [00:54<03:58,  5.96s/it]\u001b[A\n",
            " 22% 11/50 [01:00<03:53,  5.99s/it]\u001b[A\n",
            " 24% 12/50 [01:06<03:48,  6.01s/it]\u001b[A\n",
            " 26% 13/50 [01:12<03:42,  6.02s/it]\u001b[A\n",
            " 28% 14/50 [01:18<03:37,  6.04s/it]\u001b[A\n",
            " 30% 15/50 [01:24<03:31,  6.05s/it]\u001b[A\n",
            " 32% 16/50 [01:30<03:25,  6.05s/it]\u001b[A\n",
            " 34% 17/50 [01:36<03:19,  6.05s/it]\u001b[A\n",
            " 36% 18/50 [01:43<03:13,  6.05s/it]\u001b[A\n",
            " 38% 19/50 [01:49<03:07,  6.06s/it]\u001b[A\n",
            " 40% 20/50 [01:55<03:01,  6.06s/it]\u001b[A\n",
            " 42% 21/50 [02:01<02:55,  6.06s/it]\u001b[A\n",
            " 44% 22/50 [02:07<02:49,  6.07s/it]\u001b[A\n",
            " 46% 23/50 [02:13<02:43,  6.07s/it]\u001b[A\n",
            " 48% 24/50 [02:19<02:37,  6.07s/it]\u001b[A\n",
            " 50% 25/50 [02:25<02:31,  6.07s/it]\u001b[A\n",
            " 52% 26/50 [02:31<02:25,  6.08s/it]\u001b[A\n",
            " 54% 27/50 [02:37<02:19,  6.07s/it]\u001b[A\n",
            " 56% 28/50 [02:43<02:13,  6.07s/it]\u001b[A\n",
            " 58% 29/50 [02:49<02:07,  6.07s/it]\u001b[A\n",
            " 60% 30/50 [02:55<02:01,  6.07s/it]\u001b[A\n",
            " 62% 31/50 [03:01<01:55,  6.07s/it]\u001b[A\n",
            " 64% 32/50 [03:08<01:49,  6.06s/it]\u001b[A\n",
            " 66% 33/50 [03:14<01:43,  6.06s/it]\u001b[A\n",
            " 68% 34/50 [03:20<01:36,  6.05s/it]\u001b[A\n",
            " 70% 35/50 [03:26<01:30,  6.05s/it]\u001b[A\n",
            " 72% 36/50 [03:32<01:24,  6.03s/it]\u001b[A\n",
            " 74% 37/50 [03:38<01:18,  6.04s/it]\u001b[A\n",
            " 76% 38/50 [03:44<01:12,  6.04s/it]\u001b[A\n",
            " 78% 39/50 [03:50<01:06,  6.04s/it]\u001b[A\n",
            " 80% 40/50 [03:56<01:00,  6.04s/it]\u001b[A\n",
            " 82% 41/50 [04:02<00:54,  6.04s/it]\u001b[A\n",
            " 84% 42/50 [04:08<00:48,  6.04s/it]\u001b[A\n",
            " 86% 43/50 [04:14<00:42,  6.04s/it]\u001b[A\n",
            " 88% 44/50 [04:20<00:36,  6.04s/it]\u001b[A\n",
            " 90% 45/50 [04:26<00:30,  6.04s/it]\u001b[A\n",
            " 92% 46/50 [04:32<00:24,  6.05s/it]\u001b[A\n",
            " 94% 47/50 [04:38<00:18,  6.05s/it]\u001b[A\n",
            " 96% 48/50 [04:44<00:12,  6.05s/it]\u001b[A\n",
            " 98% 49/50 [04:50<00:06,  6.05s/it]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.07290954887866974, 'eval_runtime': 302.893, 'eval_samples_per_second': 0.33, 'eval_steps_per_second': 0.165, 'eval_entropy': 0.3098095703125, 'eval_num_tokens': 2457600.0, 'eval_mean_token_accuracy': 0.9903323650360107, 'epoch': 3.0}\n",
            "100% 1200/1200 [4:54:38<00:00, 14.02s/it]\n",
            "100% 50/50 [04:56<00:00,  6.06s/it]\u001b[A\n",
            "{'train_runtime': 17681.7667, 'train_samples_per_second': 0.136, 'train_steps_per_second': 0.068, 'train_loss': 0.2583534938097, 'epoch': 3.0}\n",
            "100% 1200/1200 [4:54:39<00:00, 14.73s/it]\n",
            "LoRA/QLoRA training completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/LLM-phi3-lora-finetuning\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIbld-mx4dql",
        "outputId": "02edeae6-fb3f-449f-8148-68918352474f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLM-phi3-lora-finetuning\n",
            "'=4.56.1'   data\t\t   logs        requirements.txt   src\n",
            " config     evaluation_report.md   README.md   scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/LLM-phi3-lora-finetuning\n",
        "\n",
        "# Regenerate raw + processed data in this new session\n",
        "!python scripts/generate_dataset.py --config config/config.yaml\n",
        "!python src/preprocess.py --config config/config.yaml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk4Naj2u4tHE",
        "outputId": "b4fc43ac-c4d5-49f3-fad9-629c94d50627"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLM-phi3-lora-finetuning\n",
            "Wrote 1001 examples to data/raw/mydataset.jsonl\n",
            "tokenizer_config.json: 3.44kB [00:00, 12.9MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 1.78MB/s]\n",
            "tokenizer.json: 1.94MB [00:00, 38.8MB/s]\n",
            "added_tokens.json: 100% 306/306 [00:00<00:00, 2.18MB/s]\n",
            "special_tokens_map.json: 100% 599/599 [00:00<00:00, 2.59MB/s]\n",
            "Map: 100% 1001/1001 [00:00<00:00, 1066.11 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 800/800 [00:00<00:00, 51083.08 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 100/100 [00:00<00:00, 22194.43 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 101/101 [00:00<00:00, 23534.71 examples/s]\n",
            "Preprocessing complete\n",
            "Train size: 800\n",
            "Val size  : 100\n",
            "Test size : 101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls outputs/phi-3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDnnhHv-NotL",
        "outputId": "2a58ef60-31d4-452c-b45f-5d9d5598bc10"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adapter_config.json  adapter_model.safetensors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/preprocess.py --config config/config.yaml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8BxQLaZNvAb",
        "outputId": "37cb6d36-8667-4e05-b6ec-8f12bd13783d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Map: 100% 1001/1001 [00:00<00:00, 1183.67 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 800/800 [00:00<00:00, 38694.63 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 100/100 [00:00<00:00, 21196.20 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 101/101 [00:00<00:00, 21975.66 examples/s]\n",
            "Preprocessing complete\n",
            "Train size: 800\n",
            "Val size  : 100\n",
            "Test size : 101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data_proc\n",
        "!ls data_proc/test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA9bpod8N0wE",
        "outputId": "b6d1bf07-fb33-4921-c1da-3612a22c1ccd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test  train  val\n",
            "data-00000-of-00001.arrow  dataset_info.json  state.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/run_eval.py --config config/config.yaml\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxl4KgkwN4FN",
        "outputId": "6177e99a-0728-466c-e7ad-5cd494dcaa75"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-15 10:39:48.910961: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-15 10:39:49.079910: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-15 10:39:49.128140: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768473589.380041   25951 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768473589.464726   25951 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768473590.189967   25951 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768473590.190080   25951 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768473590.190096   25951 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768473590.190104   25951 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-15 10:39:50.257480: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "Loading checkpoint shards:  50% 1/2 [00:27<00:27, 27.48s/it]^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!free -h\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-ayn3IxRAMb",
        "outputId": "27be97b0-4f61-42df-bbb6-d142245a0a82"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            12Gi       644Mi        11Gi       3.0Mi       534Mi        11Gi\n",
            "Swap:             0B          0B          0B\n"
          ]
        }
      ]
    }
  ]
}